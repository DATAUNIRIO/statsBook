[
["index.html", "Apostilas dos cursos de Estatística I e Estatística II Chapter 1 Preâmbulo 1.1 Base matemátiva", " Apostilas dos cursos de Estatística I e Estatística II Curso-R 2017-02-24 Chapter 1 Preâmbulo Essa é a apostila dos cursos de Estatística I e Estatística II da Curso-R. 1.1 Base matemátiva 1.1.1 O que são variáveis? Variáveis são simbolos que representam valores desconhecidos que podem variar dentro de um conjunto de possíveis valores. Aqui, esses símbolos serão denotados por letras maiúsculas do nosso alfabeto (X, Y, Z…). Exemplos: Velocidade marcada no velocímetro de um carro. Cor de uma bola retirada de uma urna. Número de gols sofridos pelo São Paulo no próximo jogo. Quando o processo de mensuração de uma variável é dado por um experimento aleatório, chamamos essa variável de variável aleatória. 1.1.2 Conjuntos Um conjunto é uma coleção de objetos distintos. Em geral, eles são denotados por letras maiúsculas do nosso alfabeto (A, B, C …) e são escritos como uma lista de seus elementos limitados por chaves. Exemplos: {A, B, C} {1, 3, 5} {x: x é par} Conjuntos importantes para o curso: \\(\\mathbb{N} = \\{0, 1, 2, ...\\}\\) — conjunto dos números naturais \\(\\mathbb{R} = (-\\infty, +\\infty)\\) — conjunto dos números reais 1.1.3 Somatórios e produtórios Quando estamos lidando com somas muito extensas de números ou variáveis, podemos utilizar a seguinte notação: \\(\\sum_{i=1}^{n} i = 1 + 2 + ... + n\\). Dessa forma, temos que \\(\\sum_{i=1}^{10}x = 1 + 2 + ... + 10\\) ou \\(\\sum_{i=1}^{10} X = X_1 + X_2 + X_3 + ... + X_{10}\\). De forma análoga, temos a seguinte notação para produtórios: \\(\\prod_{i=1}^{n} i = 1 \\times 2 \\times ... \\times n\\). Dessa forma, temos que \\(\\prod_{i=1}^{10}x = 1 \\times 2 \\times ... \\times 10\\) ou \\(\\prod_{i=1}^{10} X = X_1 \\times X_2 \\times X_3 \\times ... \\times X_{10}\\). 1.1.4 Vetores Neste curso, chamaremos X de vetor de tamanho n se X denotar uma sequência de n variáveis indexadas. Notação: \\(X = (X_1, X_2, ..., X_n)\\). "],
["analise-descritiva.html", "Chapter 2 Análise descritiva 2.1 Tipos de variáveis 2.2 Distribuição de frequência", " Chapter 2 Análise descritiva Os principais objetivos da análise descritiva são: analisar o comportamento das variáveis em estudo; e buscar indícios de associação entre as variáveis. 2.1 Tipos de variáveis Uma etapa primordial de qualquer análise estatística é verificar qual metodologia é mais adequada para o conjunto de dados sob análise. Para isso, é essencial conhecermos a natureza das variáveis presentes no estudo. 2.1.1 Motivação Uma médica do Instituto do Coração está interessada em associar certas características dos seus pacientes com a ocorrência de extrassístoles (batimentos cardíacos fora do ritmo). Com esse objetivo em mente, com cada paciente, ela realizou uma entrevista e uma série de exames. Destacamos a seguir algumas das variáveis coletadas Idade (anos) Sexo (M, F) Tabagismo (fuma ou não fuma) Consumo de álcool (ml por semana) Fração de ejeção (%) Frequência cardíaca (bpm) Presença de extrassístoles (sim ou não) Observe que algumas variáveis apresentam, como possíveis realizações, uma qualidade (atributo) do paciente, enquanto outras apresentam, como possíveis realizações, valores resultantes de uma contagem ou mensuração. As variáveis do primeiro tipo são chamadas qualitativas e, as do segundo, quantitativas. 2.1.2 Definição Variáveis qualitativas apresentam como possíveis realizações uma qualidade ou atributo. Se os possíveis resultados não tiverem nenhum tipo de ordenação, chamamos a variável de qualitativa nominal. Já as variáveis qualitativas cujos resultados podem ser ordenados são chamadas de qualitativas ordinais. Variáveis quantitativas apresentam como possíveis realizações valores (números) resultantes de uma contagem ou mensuração. Se o conjunto de possíveis valores dessa variável é finito ou enumerável, a variável é chamada de quantitativa discreta. Se esse conjunto é não-enumerável (um subconjunto dos números reais), a variável é chamada de quantitativa contínua. Observação: na prática, para o ajuste de modelos estatísticos, as variáveis qualitativas são transformadas em variáveis quantitativas discretas. Por exemplo, se considerarmos a variável sexo, as categorias “feminino” e “masculino” são transformadas em “0” e “1”. 2.2 Distribuição de frequência Com o objetivo de analisar o comportamento das variáveis em estudo, uma ideia inicial é estudar como os valores de cada variável estão distribuídos. Uma maneira simples de se fazer isto é construir uma tabela de frequências. 2.2.1 Exemplo 1 Vamos considerar as seguintes tabelas de frequência para a variável qualitativa X: diretor preferido entre as opções {Tarantino, Scorsese, Nolan, Fincher}. Diretor Frequência \\((n_i)\\) Proporção \\((f_i)\\) Proporção (%) Tarantino 33 0,33 33% Scorsese 22 0,22 22% Nolan 35 0,35 35% Fincher 10 0,1 10% Total 100 1 100% A frequência absoluta \\((n_i)\\) representa quantas observações há em cada categoria da variável. A proporção ou frequência relativa é a razão entre a frequência absoluta e o total de observações \\((n)\\). Esta medida é acrescentada à tabela para facilitar a comparação da frequência entre as categorias da variável e possibilita comparar tabelas de frequências (para uma mesma variável) com totais \\((n)\\) diferentes. Também podemos construir tabelas de frequências para variáveis quantitativas. Em geral, é necessário dividir o intervalo de possíveis valores dessa variável em classes. 2.2.2 Exemplo 2 Vamos considerar a variável fração de ejeção do banco de dados do Instuto do Coração. Lembrando que essa variável pode variar entre 0 e 100%, vamos dividir esse intervalo em duas classes: [0, 55) e [55, 100]. Classes Frequência \\((n_i)\\) Proporção \\((n_i)\\) Proporção (%) [0,55) 237 0,798 79,8% [55,100] 60 0,202 20,2% Total 297 1 100% "],
["medidas-de-posicao-central.html", "Chapter 3 Medidas de posição central 3.1 Média aritmética 3.2 Mediana 3.3 Moda", " Chapter 3 Medidas de posição central As medidas de posição central trazem informação sobre a localização dos dados no seu conjunto de possíveis valores, mais especificamente, onde estão centrados. 3.1 Média aritmética A média aritmética é definida pela soma das observações dividida pelo número total de observações. 3.1.1 Exemplo Sejam \\(x_1, ..., x_n\\) \\(n\\) observações de uma variável \\(X\\) qualquer. A média é dada pela expressão \\(\\frac{\\sum_{i=1}^{n}x_i}{n} = \\frac{x_1 + x_2 + ... + x_n}{n}\\) 3.2 Mediana A mediana é a observação que ocupa a posição central dos dados, quando estão ordenados de forma crescente. 3.2.1 Exemplo 1 (número ímpar de observações) Vamos considerar o seguinte conjunto de observações: 3, 7, 10, 5, 2, 1, 1. Para calcular a mediana, primeiramente ordenamos os dados: 1, 1, 2, 3, 5, 7, 10. É fácil verificar que a observação que ocupa a posição central é o valor 3. Portanto, 3 é a mediana desse conjunto de valores. 3.2.2 Exemplo 2 (número par de observações) Vamos considerar agora o seguinte conjunto de observações: 15, 3, 2, 0, 9, 17. Ordenanando os dados, temos: 0, 2, 3, 9, 15, 17. Neste caso, a mediana será dada pela média entre as duas observações centrais, isto é, (3 + 9)/2 = 6. 3.3 Moda A moda é a observação mais frequente do conjunto de valores observados. 3.3.1 Exemplo No conjunto de observações {3, 5, 10, 11, 11, 20}, a observação 11 aparece 2 vezes enquanto as demais apenas 1 vez. Portanto, 11 é a moda desse conjunto. "],
["medidas-de-dispersao.html", "Chapter 4 Medidas de dispersão 4.1 Variância 4.2 Desvio padrão", " Chapter 4 Medidas de dispersão O resumo de um conjunto de dados por uma única medida de posição central não traz informação sobre a variabilidade das observações. Um critério frequentemente usado para avaliar a dispersão de um conjunto de observações é aquele que mede a dispersão dos dados em torno da sua média. 4.1 Variância Sejam \\(x_1, x_2, ..., x_n\\) \\(n\\) observações de uma variável quantitativa \\(X\\). Seja \\(\\bar{x}\\) a média dessas observações. Vamos observar, então, os desvios das observações em relação à média \\(\\bar{x}\\), isto é, \\(x_i - \\bar{x}\\), para \\(i = 1, ..., n\\). Ideia 1: usar como medida de dispersão a soma desses desvios, isto é, \\[ \\sum_{i=1}^{n}(x_i - \\bar{x}). \\] Problema 1: para qualquer conjunto de observações \\[ \\sum_{i=1}^{n}(x_i - \\bar{x}) = 0. \\] Ideia 2: considerar a soma do quadrado dos desvios, dada por \\[ \\sum_{i=1}^{n}(x_i - \\bar{x})^2 \\] Problema 2: não podemos comparar conjuntos de observações de tamanhos diferentes. Ideta 3: utilizar a média desses desvios quadráticos. Sendo assim, definimos a medida de dispersão conhecida como variância da seguinte forma: \\[ VAR(X) = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n} \\] 4.2 Desvio padrão A utilização da variância como medida de dispersão pode ainda causar um problema de interpretação, pois a sua dimensão é igual ao quadrado da dimensão dos dados. Sendo assim, costuma-se usar o desvio padrão, defino por \\[ DP(X) = \\sqrt{VAR(X)} = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n}}. \\] "],
["quantis.html", "Chapter 5 Quantis", " Chapter 5 Quantis Vimos que a mediana é uma medida que deixa metade dos dados abaixo dela e metade acima. De modo geral, podemos definir a medida \\(q_p\\), \\(0 &lt; p &lt; 100\\), tal que \\(p%\\) das observações sejam menores que \\(q_p\\). Esta medida é chamada de quantil de ordem \\(p\\). Alguns quantis são bastante utilizados na prática. São eles \\(Q1 = q_{25\\%}\\) (primeiro quartil) \\(Q2 = q_{50\\%}\\) (mediana) \\(Q3 = q_{75\\%}\\) (terceiro quartil) Observe que os \\(q_{0\\%}\\) e \\(q_{100\\%}\\) denotam, respectivamente, o mínimo e o máximo de conjunto de dados. "],
["medidas-de-associacao-entre-duas-variaveis.html", "Chapter 6 Medidas de associação entre duas variáveis 6.1 Associação entre variáveis qualitativas 6.2 Associação entre variáveis quantitativas 6.3 Introdução 6.4 Gráficos de barras 6.5 Histogramas 6.6 Boxplots 6.7 Gráficos de dispersão 6.8 Gráfico de uma série 6.9 Gráficos mal construídos", " Chapter 6 Medidas de associação entre duas variáveis 6.1 Associação entre variáveis qualitativas Para investigar a associação entre duas variáveis qualitativas, podemos utilizar tabelas de contingência. 6.1.1 Exemplo Vamos considerar as seguintes variáveis X: salas do terceiro ano do ensino médio Y: conceitos finais na disciplina de matemática Variáveis A B C Total A 20 (69%) 16 (49%) 10 (37%) 46 (51%) B 6 (21%) 6 (18%) 1 (4%) 13 (15%) C 2 (7%) 1 (3%) 10 (37%) 13 (15%) D 1 (3%) 10 (30%) 6 (22%) 17 (19%) Total 29 (100%) 33 (100%) 27 (100%) 89 (100%) Analisando a tabela acima, verificamos que a proporção de alunos com boas notas é maior nas classes I e II. De uma forma mais geral, dizemos que as duas variáveis estão associadas. 6.2 Associação entre variáveis quantitativas Vamos definir uma medida para quantificar a associação entre duas variáveis quantitativas. Vale lembrar que existem vários tipos de associação. Aqui, vamos considerar o tipo mais simples: a relação linear. Vamos considerar um conjunto de observações bivariadas \\((x_1, y_1), ..., (x_n, y_n)\\). O coeficiente de relação linear é dado por \\[ Corr(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{(x_i - \\bar{x})}{DP(X)} \\right) \\left( \\frac{(y_i - \\bar{y})}{DP(Y)} \\right). \\] 6.3 Introdução Analisar um gráfico é uma maneira rápida e concisa de visualizar certas informações contidas em um conjunto de observações. O gráfico certo a ser utilizado em cada situação depende da informação que queremos visualizar e do tipo de variável que estamos trabalhando. Um gráfico mal muitas vezes falha em trazer com clareza a informação que queremos visualizar e, em alguns casos, pode levar a falsas evidências. 6.4 Gráficos de barras Amostra: estudantes de estatística X: cor do cabelo — Y: cor dos olhos — W: sexo Podemos associar a variável “cor dos olhos” à cor das barras do gráfico. Além disso, podemos dividir o gráfico pela variável “sexo” e comparar as frequências para homens e mulheres. 6.5 Histogramas Amostra de tamanho 400 de uma distribuição normal com média 170 e desvio padrão 8. Em vez de representar a frequência no eixo y, podemos optar pela densidade, definida pela razão entre a proporção e a amplitude de cada classe. Um histograma construído dessa forma tem área 1. Assimetria à direita Assimetria à esquerda 6.6 Boxplots Dados da temporada de Baseball de 1986 (EUA) Dados da temporada de Baseball de 1986 (EUA) 6.7 Gráficos de dispersão 6.8 Gráfico de uma série Vazão do rio Nilo de 1871 a 1970. Número de mortes acidentais nos EUA de 1973 a 1979. 6.9 Gráficos mal construídos "],
["probabilidade.html", "Chapter 7 Probabilidade", " Chapter 7 Probabilidade A interpretação da probabilidade pode variar de pessoa para pessoa. Para alguns, a probabilidade é vista como o limite de uma sequência de frequências relativas. Essa é a visão frequentista da probabilidade. Para outros, a probabilidade é uma medida subjetiva de incerteza. Essa é a visão Bayesiana. 7.0.1 Espaço amostral Definição. O espaço amostral, comumente denotado por \\(\\Omega\\), é o conjunto de todos os possíveis resultados de um experimento aleatório. Chamamos de evento qualquer subconjunto de interesse do espaço amostral. Definição. Chamamos de evento complementar do evento \\(A\\), simbolicamente \\(A^c\\), o conjunto formado por todos os elementos que não pertencem a \\(A\\). 7.0.2 União e intersecção de eventos Definição. Chamamos de união dos eventos \\(A\\) e \\(B\\), simbolicamente \\(A \\cup B\\), o conjunto formado pelos elementos que pertencem ao evento \\(A\\) ou ao evento \\(B\\). Definição. Chamamos de intersecção dos eventos \\(A\\) e \\(B\\), simbolicamente, \\(A \\cap B\\), o conjunto formado pelos pontos que pertencem ao evento \\(A\\) e ao evento \\(B\\). 7.0.3 Partição de um espaço amostral Definição. Sejam \\(A_1, A_2, ..., A_n\\) uma coleção de eventos tais que \\(A_1 \\cup ...\\cup A_n = \\Omega\\) e \\(A_1 \\cap A_n = \\varnothing\\), \\(\\forall i \\neq j\\). Chamamos essa coleção de partição do espaço amostral. 7.0.4 Algumas propriedades Seja \\(A\\) um sub-conjunto de \\(\\Omega\\). \\(0 \\leq P(A) \\leq 1\\) \\(P(\\Omega) = 1\\) e \\(P(\\varnothing) = 0\\) \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) 7.0.5 Chance A chance do evento \\(A\\) é definida pela razão entre as probabilidades de ocorrência e não-ocorrência do evento, isto é, \\[ \\text{Chance de A} = \\frac{P(A)}{P(A^c)} = \\frac{P(\\text{A ocorrer})}{P(\\text{A não ocorrer})}. \\] Observe que a chance de um evento pode variar de 0 a \\(+ \\infty\\). 7.0.6 Condicionalidade Definição. Para dois eventos quaisquer \\(A\\) e \\(B\\), sendo \\(P(B) &gt; 0\\), definimos a probabilidade condicional de \\(A\\) dado \\(B\\), denotada por \\(P(A|B)\\), como sendo \\[ P(A|B) = \\frac{P(A\\cap B)}{P(B)}. \\] 7.0.7 Independência Da definição de probabilidade condicional, temos que \\[ P(A \\cap B) = P(A|B)P(B). \\] Se a ocorrência de um evento \\(B\\) não trouxer nenhuma informação sobre a ocorrência ou não de um evento \\(A\\), dizemos que \\(A\\) e \\(B\\) são independentes. Formalmente, dizemos que dois eventos quaisquer são independentes se \\[ P(A \\cap B) = P(A)P(B). \\] 7.0.8 Teorema de Bayes O Teorema de Bayes é dado pela seguinte expressão: \\[ P(A|B) = \\frac{P(B|A)P(A)}{P(B)}. \\] 7.0.8.1 Resultado Seja \\(A\\) um evento de \\(\\Omega\\) e \\(C_1, ..., C_n\\) uma partição desse espaço amostral. Então \\[ P(A) = \\sum_{i=1}^{n} P(A|C_i)P(C_i) \\] Pelo resultado, podemos escrever o Teorema de Bayes como \\[ P(C_i|A) = \\frac{P(A|C_i)P(C_i)}{\\sum_{i=1}^{n} P(A|C_i)P(C_i)}. \\] 7.0.8.2 Exemplo Em uma fábrica de parafusos, as máquinas \\(A\\), \\(B\\) e \\(C\\) produzem 25%, 35% e 40% do total, respectivamente. Da produção de cada máquina 5%, 4% e 2%, respectivamente, são parafusos defeituosos. Escolhe-se ao acaso um parafuso e verifica-se que é defeituoso. Qual a probabilidade de que o parafuso venha da máquina \\(A\\)? Vamos definir os seguintes eventos: \\(A\\): o parafuso foi produzido pela máquina \\(A\\) \\(B\\): o parafuso foi produzido pela máquina \\(B\\) \\(C\\): o parafuso foi produzido pela máquina \\(C\\) \\(D\\): o parafuso é defeituoso Pelo enunciado, sabemos que: \\(P(A) = 0.25\\), \\(P(B) = 0.35\\), \\(P(C) = 0.40\\), \\(P(D|A) = 0.05\\), \\(P(D|B) = 0.04\\) e \\(P(D|C) = 0.02\\). Dessa forma, \\[ P(A|D) = \\frac{P(D|A)P(A)}{P(D)} = \\frac{P(D|A)P(A)}{P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)} = \\] \\[ = \\frac{0.05\\cdot 0.25}{0.05\\cdot0.25 + 0.04\\cdot0.35 + 0.02\\cdot0.40} = 0.3623 = 36,23\\%. \\] "],
["variaveis-aleatorias.html", "Chapter 8 Variáveis aleatórias 8.1 Variáveis aleatórias discretas 8.2 Variáveis aleatórias contínuas 8.3 Associação entre variáveis aleatórias 8.4 Distribuição Uniforme 8.5 Distribuição Bernoulli 8.6 Distribuição Binomial 8.7 Distribuição de Poisson 8.8 Distribuição Uniforme 8.9 Distribuição Normal 8.10 Distribuição Exponencial 8.11 Distribuição Gama 8.12 Inferência Estatística 8.13 Amostragem", " Chapter 8 Variáveis aleatórias Uma variável aleatória (v.a.) é uma função \\(X\\) definida no espaço amostral \\(\\Omega\\) e com valores num conjunto de pontos de \\(\\mathbf{R}\\). Se esse conjunto de pontos é enumerável, a variável \\(X\\) é discreta. Se o conjunto é não-enumerável, \\(X\\) é contínua. 8.1 Variáveis aleatórias discretas 8.1.1 Função de probabilidade Definição. À função que, para cada valor possível da variável aleatória discreta \\(X\\), associa a sua probabilidade de ocorrência, damos o nome de função de probabilidade de \\(X\\). 8.1.2 Esperança de uma variável aleatória discreta Definição. Dada a v. a. discreta \\(X\\), assumindo os valores \\(x_1, ..., x_n\\), chamamos de esparança de \\(X\\) o valor \\[ E(X) = \\sum_{i}^{n}x_i p(x_i) = \\sum_{i}^{n}x_i P(X = x_i). \\] 8.1.3 Variância de uma variável aleatória discreta Definição. Chamamos de variância da v. a. \\(X\\) o valor \\[ VAR(X) = \\sum_{i}^{n}(x_i - E(X))^2 p(x_i) = E((X - E(X))^2). \\] Observe que, abrindo a expressão acima, podemos escrever \\[ VAR(X) = E(X^2) - (E(X))^2. \\] O desvio padrão de \\(X\\) é dado pela raiz quadrada positiva da variância. 8.1.4 Função de distribuição acumulada Definição. Dada a variável aleatória \\(X\\), chamaremos de função de distribuição acumulada, ou simplesmente função de distribuição, a função \\[ F(x) = P(X \\leq x). \\] 8.2 Variáveis aleatórias contínuas Para variáveis aleatórias contínuas não podemos definir uma função de probabilidade, pois \\[ P(X = x) = 0, \\] para qualquer possível valor \\(x\\) de qualquer v. a. contínua \\(X\\). Alternativamente, definiremos a chamada função densidade de probabilidade. 8.2.1 Função densidade de probabilidade A probabilidade de uma v. a. contínua \\(X\\) com função densidade de probabilidade \\(f(x)\\) pertencer a um intervalo \\([a,b]\\), denotada por \\(P(a \\leq X \\leq b)\\), é dada pela área abaixo da curva de \\(f(x)\\) no intervalo \\([a,b]\\). Dada uma v. a. contínua \\(X\\), também podemos definir as quantidades \\(E(X)\\) e \\(VAR(X)\\). Não vamos, no entanto, entrar em detalhes sobre como obtê-las. Vale lembrar que a definição dada para a função de distribuição acumulada também vale para v. a. contínuas. 8.3 Associação entre variáveis aleatórias Definição. Sejam \\(X\\) e \\(Y\\) duas v. a. discretas quaisquer. Chamamos de função de probabilidade conjunta a função dada por \\[ p(x, y) = P(X = x, Y = y). \\] Analogamente, podemos pensar na função de densidade conjunta no caso contínuo, denotada por \\(f(x,y)\\). Definição. Dizemos que as variáveis \\(X\\) e \\(Y\\) são independentes se, e somente se, \\[ p(x, y) = P(X = x, Y = y) = P(X = x)P(Y = y), \\forall x, y. \\] e, analogamente, no caso contínuo, se \\[ f(x, y) = f(x)f(y), \\quad \\forall x, y. \\] Definição. Sejam \\(X\\) e \\(Y\\) v. a. discretas. A distribuição condicional de \\(X|Y=y\\) é dada por \\[ P(X = x | Y = y) = \\frac{P(X = x, Y = y)}{P(Y = y)} \\] Analogamente, no caso contínuo, temos \\[ f(x|y) = \\frac{f(x, y)}{f(y)}. \\] 8.4 Distribuição Uniforme A variável aleatória \\(X\\), assumindo os valores \\(x_1, ..., x_n\\), tem distribuição uniforme se \\[ p(x_i) = P(X = x_i) = \\frac{1}{n}, \\forall 1, ..., n. \\] 8.5 Distribuição Bernoulli A variável aleatória \\(X\\), que assume apenas os valores 0 ou 1, com função de probabilidade dada por \\(p(x) = p\\), se \\(x = 1\\), e \\(p(x) = 1 - p\\), se \\(x = 0\\), é chamada v. a. de Bernoulli. Aqui, consideramos \\(0 &lt; p &lt; 1\\). Temos que \\(E(X) = p\\) e \\(VAR(X) = p(1 - p)\\). 8.6 Distribuição Binomial Sejam \\(X_1, ..., X_n\\) \\(n\\) variáveis aleatórias independentes com distribuição \\(Bernoulli(p)\\). A variável aleatória \\(Y\\) definida por \\[ Y = \\sum_{i=1}^{n} X_i \\] tem distribuição Binomial. Simbolicamente, escrevemos \\(Y \\sim Binomial(n, p)\\). A função de probabilidade de \\(Y\\) é dada por \\[ p(x) = P(X = x) = \\binom{n}{p} p^x (1-p)^{n-x}. \\] Temos que \\(E(X) = np\\) e \\(VAR(X) = np(1 - p)\\). 8.7 Distribuição de Poisson Dizemos que a v. a. \\(X\\) tem distribuição Poisson com parâmetro \\(\\lambda &gt; 0\\) se \\[ P(X = x) = \\frac{\\exp(- \\lambda)\\lambda^x}{x!}, \\quad x = 0, 1, 2, ... \\] Temos que \\(E(X) = VAR(X) = \\lambda\\). 8.8 Distribuição Uniforme Sejam \\(a\\) e \\(b\\) números reais e \\(X\\) uma variável aleatória com função densidade de probabilidade dada por \\[ f(x) = \\frac{1}{b-a}, \\quad a &lt; x &lt; b. \\] Dizemos que \\(X\\) segue a distribuição uniforme contínua no intervalo \\((a,b)\\). Simbolicamente, \\(X \\sim U(a,b)\\). Temos que \\(E(X) = \\frac{a + b}{2}\\) e \\(VAR(X) = \\frac{(b-a)^2}{12}\\). 8.9 Distribuição Normal Seja \\(X\\) uma variável aleatória contínua com função densidade de probabilidade dada por \\[ f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\] Dizemos que \\(X\\) segue a distribuição Normal com média \\(\\mu \\in \\mathbf{R}\\) e variância \\(\\sigma^2 &gt; 0\\). Simbolicamente, \\(X \\sim N(\\mu, \\sigma^2)\\). 8.9.1 Normal padrão Seja \\(X \\sim N(\\mu, \\sigma^2)\\) e \\(Z\\) uma v. a. definida por \\[ Z = \\frac{X - \\mu}{\\sigma}. \\] Então, \\(Z \\sim N(0,1)\\) é dita ser uma Normal padrão. 8.10 Distribuição Exponencial Seja \\(\\lambda &gt; 0\\) e \\(X\\) uma variável aleatória com função densidade de probabilidade dada por \\[ f(x) = \\lambda e^{-\\lambda x}, \\quad x &gt; 0. \\] Dizemos então que \\(X\\) segue a distribuição exponencial. Simbolicamente, \\(X \\sim Exp(\\lambda)\\). Temos que \\(E(X) = \\frac{1}{\\lambda}\\) e \\(VAR(X) = \\frac{1}{\\lambda^2}\\). 8.11 Distribuição Gama Sejam \\(a\\) e \\(b\\) números reais positivos e \\(X\\) uma variável aleatória com função densidade de probabilidade dada por \\[ f(x) = \\frac{b^a}{\\Gamma (a)} x^{a-1} e^{-b x}, \\quad x &gt; 0. \\] Dizemos então que \\(X\\) segue a distribuição Gama. Simbolicamente, \\(X \\sim Gama(a, b)\\). Temos que \\(E(X) = \\frac{a}{b}\\) e \\(VAR(X) = \\frac{a}{b^2}\\). 8.12 Inferência Estatística O principal objetivo da análise inferencial é fazer afirmações sobre alguma característica de interesse da população. Definição. População é o conjunto de todos os elementos ou resultados sob investigação. Uma amostra é qualquer subconjunto da população. A cada elemento da população damos o nome de unidade amostral. 8.13 Amostragem Podemos dividir os procedimentos científicos de obtenção de dados amostrais em três grandes grupos. Levantamento amostrais Planejamento de experimento Levantamento observacional Aqui, utilizaremos a técnica de amostragem conhecida por amostragem aleatória simples. Definição. Uma amostra aleatória simples de tamanho \\(n\\) de uma variável aleatória \\(X\\) qualquer é o conjunto de \\(n\\) variáveis aleatórias independentes \\(X_1, ..., X_n\\) cada uma com a mesma distribuição de \\(X\\). "],
["estimacao-pontual.html", "Chapter 9 Estimação pontual 9.1 Propriedades de um estimador 9.2 Estimador de máxima verossimilhança 9.3 Construção de um IC 9.4 Construçao de um teste de hipóteses 9.5 Poder de um teste", " Chapter 9 Estimação pontual Definição. Um parâmetro é uma medida utilizada para descrever uma característica da população. Definição. Um estimador é uma função da amostra \\((X_1, ..., X_n)\\) definida com o objetivo de se fazer inferência sobre um parâmetro populacional. 9.1 Propriedades de um estimador Definição. Um estimador \\(T\\) é dito não-enviesado (não-viciado) para \\(\\theta\\) se \\[ E(T) = \\theta, \\quad \\text{para todo } \\theta. \\] Definição. Um estimador não-enviesado \\(T\\) é dito consistente se \\[ VAR(T) \\longrightarrow 0 \\quad \\text{quando} \\quad n \\longrightarrow +\\infty. \\] Definição. Se \\(T\\) e \\(S\\) são dois estimadores não-enviesados de \\(\\theta\\) e \\[ VAR(T) &lt; VAR(S), \\] então dizemos que \\(T\\) é mais eficiente que \\(S\\). Definição. Chama-se erro quadrático médio do estimador \\(T\\) o valor \\[ EQM(T, \\theta) = VAR(T) + (Viés(T))^2, \\] em que \\[ Viés(T) = E(T) - \\theta. \\] 9.2 Estimador de máxima verossimilhança Definição. Seja \\(X_1, ..., X_n\\) uma a. a. de uma v. a. \\(X\\). A função de verossimilhança é definida por \\[ L(\\theta) = L(\\theta; x_1, ..., x_n) = f(x_1; \\theta) ... f(x_n; \\theta). \\] O estimador de máxima verossimilhança é o valor \\(\\hat{\\theta}\\) que maximiza \\(L(\\theta)\\). 9.3 Construção de um IC Como exemplo, vamos construir um intervalo de confiança para a média populacional. Vamos supor que \\(X_1, ..., X_n\\) seja uma a. a. da v. a. \\(X \\sim N(\\mu, \\sigma^2)\\). A partir desta amostra, queremos construir um intervalo de confiança para \\(\\mu\\), isto é, um intervalo que tenha grande probabilidade de conter o verdadeiro valor de \\(\\mu\\). Sabemos que \\(\\bar{X}\\) é um bom estimador para \\(\\mu\\). Sendo assim, é razoável pensar em minimizar o erro dado por \\[ \\text{erro } = |\\bar{X} - \\mu|. \\] Mais precisamente, podemos que a probabilidade desse erro ser menor que um determinado \\(\\epsilon\\) seja grande, digamos, 95%. Simbolicamente, temos \\[ P(|\\bar{X} - \\mu| &lt; \\epsilon) = 95\\%. \\] Desenvolvendo a expressão acima, temos que \\[ P(\\bar{X} - \\epsilon &lt; \\mu &lt; \\bar{X} + \\epsilon) = 95\\%. \\] Portanto, um intervalo para \\(\\mu\\) com confiança de 95% é dado por \\((\\bar{X} - \\epsilon, \\bar{X} + \\epsilon)\\). Não é difícil mostrar que, neste caso, \\[ \\epsilon = z(95\\%) \\sqrt{\\frac{\\sigma^2}{n}}, \\] em que \\(z(95\\%)\\) é o número que satisfaz \\[ P(-z(95\\%) &lt; Z &lt; z(95\\%)) = 95\\%. \\] Neste contexto, o valor \\(95\\%\\) é chamado coeficiente de confiança do intervalo. Em um caso geral, denotando essa quantidade por \\(\\gamma\\), o intervalo de confiança para a média \\(\\mu\\) é dado por \\[ IC(\\mu, \\gamma) = \\left(\\bar{X} - z(\\gamma) \\sqrt{\\frac{\\sigma^2}{n}}, \\bar{X} + z(\\gamma) \\sqrt{\\frac{\\sigma^2}{n}}\\right). \\] 9.4 Construçao de um teste de hipóteses Vamos motivar a construçãode um teste de hipóteses a partir do seguinte exemplo. Há o interesse em saber se um astrólogo consegue acertar o signo de pessoas escolhidas ao acaso a partir de informações sobre a personalidade de cada uma delas. Pergunta: o índice de acerto do astrólogo é maior que aquele que esperaríamos se ele estivesse respondendo ao acaso? Temos que a probabilidade de acertar um signo ao acaso é \\(\\frac{1}[12]\\). Vamos supor que uma amostra de 100 pessoas de uma certa população foi coletada e informações sobre a personalidade de cada uma foram disponibilizadas. Sendo assim, baseado nessas informações, o astrólogo vai inferir o signo da pessoa e, então, podemos definir, para \\(i = 1, ..., n\\), a seguinte variável \\[ X_i = 1, \\text{ se ele acerta o signo da i-ésima pessoa e} \\quad X_i = 0, \\text{ caso contrário.} \\] Portanto, \\(X_i \\sim Bernoulli(p)\\), \\(i = 1, ..., n\\), e queremos fazer inferência sobre \\(p\\). 9.4.1 Hipóteses Dado o problema apresentado, podemos pensar em testar as seguintes hipóteses \\(H_0\\): “não existe relação entre o signo e a personalidade da pessoa” ou “o índice de acerto do astrólogo não é melhor do que o acaso (1/12)”; e \\(H_A\\): “existe relação entre o signo e a personalidade da pessoa” ou “o índice de acerto do astrólogo é melhor do que o acaso (1/12)”. Matematicamente, podemos reescrever \\(H_0\\) e \\(H_A\\) como \\(H_0: p \\leq \\frac{1}{2}\\) \\(H_A: p &gt; \\frac{1}{2}\\). No contexto de testes de hipóteses, chamamos \\(H_0\\) de hipótese nula e \\(H_A\\) de hipótese alternativa. 9.4.2 Erros Ao escolher por uma das hipóteses, quais erros podemos cometer? ERRO DO TIPO I: rejeitar a hipótese nula dada que ela é verdadeira. ERRO DO TIPO II: aceitar a hipótese nula dado que ela é falsa. Podemos calcular as probabilidades de cada um destes errros: \\(\\alpha\\): probabilidade do erro do tipo I \\(\\beta\\): probabilidade do erro do tipo II A quantidade \\(\\alpha\\) também é conhecida como nível de significância do teste. 9.4.3 Estatística do teste O procedimento usual de um teste de hipóteses consiste em encontrar um intervalo chamado de Região crítica (RC), tal que \\[ \\hat{p} \\in RC \\longrightarrow \\text{rejeitamos } H_0, \\] em que \\(\\hat{p}\\) é uma estatimativa de \\(p\\). Para isso, precisamos definir a estatística do teste. Neste exemplo, essa estatística é dada por \\[ \\hat{p} = \\frac{\\sum_{i=1}^{n}X_i}{n}, \\] de tal forma que \\[ \\hat{p} \\sim N\\left( p, \\frac{p(1-p)}{n} \\right). \\] 9.4.4 Construção da região crítica e conclusão do teste Temos que \\[ P\\left(\\hat{p} \\in RC \\hspace{2mm} | \\hspace{2mm} H_o \\text{ é verdadeira}\\right) = \\alpha \\] P( c | p = ) = ] Realizando a padronização normal, temos \\[ P\\left(Z \\geq \\frac{c - \\frac{1}{12}}{0,0276} \\hspace{2mm} | \\hspace{2mm} p = \\frac{1}{12}\\right) = \\alpha. \\] Se fixarmos \\(\\alpha = 0.05\\), temos que \\[ \\frac{c - \\frac{1}{12}}{0,0276} = 1,645 \\] e, portanto, \\(c = 0,1287\\). Assim, \\[ RC = [12,87\\%, 100\\%]. \\] Dessa forma, se a estimativa \\(\\hat{p}\\) for maior que 12,87%, rejeitamos \\(H_0\\) com um nível de significância de 5%. 9.5 Poder de um teste Chamamos de poder de um teste a probabilidade de rejeitar \\(H_0\\) dado que ela é falsa, isto é, \\[ P\\left(T(X_1, ..., X_n) \\in RC \\hspace{2mm} | \\hspace{2mm} H_0 \\text{ é falsa}\\right) = 1 - \\beta, \\] em que \\(T\\) é a estatística do teste e \\(\\beta\\) é o erro do tipo II. "]
]
